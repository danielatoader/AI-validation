{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 12:49:03.695347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-08 12:49:03.695385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-08 12:49:03.696558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-08 12:49:03.703184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 12:49:04.450924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-08 12:49:05.345187: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.383426: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.383666: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.385223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.385435: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.385640: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.468296: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.468535: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.468681: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-03-08 12:49:05.468691: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-03-08 12:49:05.468813: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-08 12:49:05.468975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Version:  2.15.0\n",
      "Eager mode:  True\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Import relevant modules\n",
    "# ImagePrediction is a helper module (helpers/image_models) that assists with setting up the image recognition models\n",
    "# and getting a prediction.\n",
    "from helpers.image_models import ImagePrediction\n",
    "# Ground truth helper so we can see the ground truth of an Imagenet image.\n",
    "from validate_ground_truth.imagenet_ground_truth import ImagenetGroundTruth\n",
    "# Instantiates the ImagePrediction object with the vgg16 model\n",
    "predictor = ImagePrediction(model_name=\"vgg16\")\n",
    "# Instantiates the ImagenetGroundTruth object\n",
    "ground_truth = ImagenetGroundTruth()\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n02120079', 'Arctic_fox', 0.9021174), ('n02134084', 'ice_bear', 0.0374203), ('n02114548', 'white_wolf', 0.026164168), ('n02441942', 'weasel', 0.025217617), ('n02326432', 'hare', 0.0026364862), ('n02111889', 'Samoyed', 0.0025606712), ('n02109961', 'Eskimo_dog', 0.0014539941), ('n02110185', 'Siberian_husky', 0.0006840576), ('n02442845', 'mink', 0.00034034965), ('n02114367', 'timber_wolf', 0.0002977582)]\n"
     ]
    }
   ],
   "source": [
    "# Gets the fitness prediction for the arctic fox image.\n",
    "arctic_fox_loc = \"./initial_test_set/arctic-fox.jpg\"\n",
    "arctic_fox = predictor.get_prediction(arctic_fox_loc)\n",
    "print(arctic_fox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image object from the arctic-fox jpg\n",
    "arctic_fox = Image.open(arctic_fox_loc)\n",
    "# Flip the image so it's upside down\n",
    "af_flipped = arctic_fox.transpose(method=Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "# Save the image\n",
    "output_flipped = \"output/af_flipped.jpg\" \n",
    "af_flipped.save(output_flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n02134084', 'ice_bear', 0.19055848), ('n03888257', 'parachute', 0.17134756), ('n02120079', 'Arctic_fox', 0.044043142), ('n01796340', 'ptarmigan', 0.03144516), ('n02441942', 'weasel', 0.017049879), ('n03958227', 'plastic_bag', 0.016838005), ('n03188531', 'diaper', 0.015459845), ('n02058221', 'albatross', 0.013839627), ('n03743016', 'megalith', 0.011456719), ('n03344393', 'fireboat', 0.0114172725)]\n"
     ]
    }
   ],
   "source": [
    "# Show us the prediction for the flipped image .. interesting outcome\n",
    "print(predictor.get_prediction(output_flipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image object from the arctic-fox jpg\n",
    "arctic_fox = Image.open(arctic_fox_loc)\n",
    "# Flip the image so it's upside down\n",
    "af_flipped = arctic_fox.effect_spread(25)\n",
    "# Save the image\n",
    "output_spread = \"output/af_spread.jpg\"\n",
    "af_flipped.save(output_spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n03888257', 'parachute', 0.14076778), ('n09288635', 'geyser', 0.08659609), ('n02120079', 'Arctic_fox', 0.055041064), ('n02441942', 'weasel', 0.04239273), ('n03743016', 'megalith', 0.035429187), ('n04228054', 'ski', 0.028895907), ('n01796340', 'ptarmigan', 0.024988918), ('n02134084', 'ice_bear', 0.023643998), ('n03344393', 'fireboat', 0.020294352), ('n03388043', 'fountain', 0.01771445)]\n"
     ]
    }
   ],
   "source": [
    "# Show us the prediction for the flipped image .. interesting outcome\n",
    "print(predictor.get_prediction(output_spread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 files belonging to 1 classes.\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "Filename: arctic-fox.jpg\n",
      "Prediction: [('n02120079', 'Arctic_fox', 0.9508856)]\n",
      "Filename: castle.jpg\n",
      "Prediction: [('n02980441', 'castle', 0.97413325)]\n",
      "Filename: iguana.jpg\n",
      "Prediction: [('n01677366', 'common_iguana', 0.97907984)]\n",
      "Filename: llama.jpg\n",
      "Prediction: [('n02437616', 'llama', 0.96955395)]\n",
      "Filename: salmon.jpg\n",
      "Prediction: [('n02536864', 'coho', 0.87779164)]\n",
      "Filename: siamese_cat.jpg\n",
      "Prediction: [('n02123597', 'Siamese_cat', 0.9406736)]\n",
      "Filename: tennis_racket.jpg\n",
      "Prediction: [('n04039381', 'racket', 0.88523024)]\n",
      "Filename: tiger.jpg\n",
      "Prediction: [('n02129604', 'tiger', 0.9228465)]\n",
      "Filename: truck.jpg\n",
      "Prediction: [('n04467665', 'trailer_truck', 0.83496106)]\n",
      "Filename: wolf.jpg\n",
      "Prediction: [('n02114367', 'timber_wolf', 0.8401957)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pathlib\n",
    "from helpers.image_models import decode_predictions\n",
    "from pprint import pprint\n",
    "\n",
    "dataset_path = pathlib.Path(os.getcwd() + \"/initial_test_set\")\n",
    "image_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path.as_posix(), \n",
    "    image_size=(224, 224), \n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# get predictions with filenames\n",
    "predictions = predictor.model.predict(image_dataset)\n",
    "\n",
    "decoded = decode_predictions(predictions, top=1)\n",
    "\n",
    "for i, image in enumerate(image_dataset.file_paths):\n",
    "    print(f\"Filename: {image.split('/')[-1]}\")\n",
    "    print(f\"Prediction: {decoded[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 transformation functions\n",
    "# 1. flip\n",
    "def flip_image(image):\n",
    "    return image.transpose(method=Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "# 2. rotate\n",
    "def rotate_image(image, degrees):\n",
    "    return image.rotate(degrees)\n",
    "# 3. zoom\n",
    "def zoom_image(image, zoom_factor):\n",
    "    return image.resize((int(image.width * zoom_factor), int(image.height * zoom_factor)))\n",
    "# 4. brightness\n",
    "def brightness_image(image, factor):\n",
    "    return image.point(lambda p: p * factor)\n",
    "# 5. contrast\n",
    "def contrast_image(image, factor):\n",
    "    return image.point(lambda p: p * factor)\n",
    "# 6. saturation\n",
    "def saturation_image(image, factor):\n",
    "    return image.point(lambda p: p * factor)\n",
    "# 7. hue\n",
    "def hue_image(image, factor):\n",
    "    return image.point(lambda p: p * factor)\n",
    "# 8. shear\n",
    "def shear_image(image, factor):\n",
    "    return image.transform(image.size, Image.AFFINE, (1, factor, 0, 0, 1, 0))\n",
    "# 9. translate\n",
    "def translate_image(image, x, y):\n",
    "    return image.transform(image.size, Image.AFFINE, (1, 0, x, 0, 1, y))\n",
    "# 10. spread\n",
    "def spread_image(image, factor):\n",
    "    return image.effect_spread(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically generate transformed images for each image in the dataset and save them to a new directory\n",
    "def generate_transformed_images(dataset_path, output_path, transformations):\n",
    "    for subdir, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            image = Image.open(file_path)\n",
    "            for transform in transformations:\n",
    "                transformed_image = transform(image)\n",
    "                output_file_path = os.path.join(output_path, f\"{file.split('.')[0]}_{transform.__name__}.jpg\")\n",
    "                transformed_image.save(output_file_path)\n",
    "\n",
    "generate_transformed_images(dataset_path, \"output_set/test\", [flip_image, rotate_image, zoom_image, brightness_image, contrast_image, saturation_image, hue_image, shear_image, translate_image, spread_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset_path = pathlib.Path(os.getcwd() + \"/output_set\")\n",
    "transformed_image_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    transformed_dataset_path.as_posix(), \n",
    "    image_size=(224, 224), \n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# create a new dataset from the transformed images\n",
    "predictions = predictor.model.predict(transformed_image_dataset)\n",
    "\n",
    "decoded = decode_predictions(predictions, top=1)\n",
    "\n",
    "for i, image in enumerate(transformed_image_dataset.file_paths):\n",
    "    print(f\"Filename: {image.split('/')[-1]}\")\n",
    "    print(f\"Prediction: {decoded[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs-F6TTcUyJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
