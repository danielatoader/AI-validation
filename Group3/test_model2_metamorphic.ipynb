{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa476b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:00:01.726793Z",
     "start_time": "2024-04-05T14:00:01.698444Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import convert_sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# define a XGBoost classifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore runtime warnings\n",
    "# Temporarily adjust pandas display settings for large DataFrames\n",
    "pd.set_option('display.max_rows', 100)  # Ensure 100 rows can be displayed\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns can be displayed\n",
    "pd.set_option('display.width', None)  # Automatically adjust display width to terminal size\n",
    "pd.set_option('display.max_colwidth', None)  # Ensure full width of column content is shown\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  # Format the float numbers for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e81b41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:01:17.968561Z",
     "start_time": "2024-04-05T14:01:17.947514Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data/synth_data_for_training.csv')\n",
    "y = data['checked']\n",
    "X = data.drop(['checked'], axis=1)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529b8619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f68f63d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:01:27.887245Z",
     "start_time": "2024-04-05T14:01:27.881521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ONNX modeL:  0.7870304468169237\n",
      "Precision of the ONNX model: 0.29943820224719103\n",
      "Recall of the ONNX model: 0.8426877470355731\n",
      "F1 score of the ONNX model: 0.4418652849740933\n"
     ]
    }
   ],
   "source": [
    "# Let's load the model\n",
    "new_session = rt.InferenceSession(\"model_2.onnx\")\n",
    "\n",
    "y_pred_onnx2 =  new_session.run(None, {'X': X.values.astype(np.float32)})\n",
    "\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y, y_pred_onnx2[0])\n",
    "# Calculate F1 score, precision, and recall\n",
    "f1_model = f1_score(y, y_pred_onnx2[0]) # You can change average method based on your need\n",
    "precision_model = precision_score(y, y_pred_onnx2[0])\n",
    "recall_model = recall_score(y, y_pred_onnx2[0])\n",
    "\n",
    "print('Accuracy of the ONNX modeL: ', accuracy_onnx_model)\n",
    "print('Precision of the ONNX model:', precision_model)\n",
    "print('Recall of the ONNX model:', recall_model)\n",
    "print('F1 score of the ONNX model:', f1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc5150b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8886, 2494],\n",
       "       [ 199, 1066]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "confusion_matrix(y, y_pred_onnx2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b05f047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:01:27.891348Z",
     "start_time": "2024-04-05T14:01:27.888094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checked\n",
       "0   0.9000\n",
       "1   0.1000\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how imbalanced the datasets is\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b4ba36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:03:04.611721Z",
     "start_time": "2024-04-05T14:03:04.151135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean likelihood for 0 developments in PLA history: 0.3404891435974622\n",
      "Mean likelihood for 25 developments in PLA history: 0.2581012699999042\n"
     ]
    }
   ],
   "source": [
    "# Metamorphic testing: (Other than fairness testing)\n",
    "# If a value changes then the prediction likelihood should change too in line with the purpose of the model \n",
    "# pla_historie_ontwikkeling 0 or 25 // number of developments in PLA history\n",
    "\n",
    "# Load the model\n",
    "testing_session = rt.InferenceSession(\"model_2.onnx\")\n",
    "\n",
    "\n",
    "# Initialize variables to store likelihoods\n",
    "likelihoods_0 = []\n",
    "likelihoods_25 = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for 0 developments in PLA history\n",
    "    X_sample_0 = X_sample.copy()\n",
    "    X_sample_0['pla_historie_ontwikkeling'] = 0\n",
    "    y_proba_0 = testing_session.run(None, {'X': X_sample_0.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Make predictions for 25 developments in PLA history\n",
    "    X_sample_25 = X_sample.copy()\n",
    "    X_sample_25['pla_historie_ontwikkeling'] = 25\n",
    "    y_proba_25 = testing_session.run(None, {'X': X_sample_25.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Append the likelihoods for both age groups\n",
    "    likelihoods_0.append([y_proba_0[1]])  # Probability of class 1 (fraud) for 0 developments in PLA history\n",
    "    likelihoods_25.append([y_proba_25[1]])  # Probability of class 1 (fraud) for 25 developments in PLA history\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_0 = np.array(likelihoods_0)\n",
    "likelihoods_25 = np.array(likelihoods_25)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_0 = np.mean(likelihoods_0)\n",
    "mean_likelihood_25 = np.mean(likelihoods_25)\n",
    "\n",
    "print(\"Mean likelihood for 0 developments in PLA history:\", mean_likelihood_0)\n",
    "print(\"Mean likelihood for 25 developments in PLA history:\", mean_likelihood_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "716dba05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:03:06.555848Z",
     "start_time": "2024-04-05T14:03:06.113795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean likelihood for a client that has shown up for meetings: 0.2187287717008836\n",
      "Mean likelihood for no show client: 0.27761307624358345\n"
     ]
    }
   ],
   "source": [
    "# contacten_onderwerp_no_show // Contact subject client has not shown up for meeting\n",
    "likelihoods_show = []\n",
    "likelihoods_noshow = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for a client that has shown up for meetings\n",
    "    X_sample_show = X_sample.copy()\n",
    "    X_sample_show['contacten_onderwerp_no_show'] = 0.0\n",
    "    y_proba_show = testing_session.run(None, {'X': X_sample_show.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Make predictions for no show client\n",
    "    X_sample_noshow = X_sample.copy()\n",
    "    X_sample_noshow['contacten_onderwerp_no_show'] = 1.0\n",
    "    y_proba_noshow = testing_session.run(None, {'X': X_sample_noshow.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Append the likelihoods for both age groups\n",
    "    likelihoods_show.append([y_proba_show[1]])  # Probability of class 1 (fraud) for a client that has shown up for meetings\n",
    "    likelihoods_noshow.append([y_proba_noshow[1]])  # Probability of class 1 (fraud) for no show client\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_show = np.array(likelihoods_show)\n",
    "likelihoods_noshow = np.array(likelihoods_noshow)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_show = np.mean(likelihoods_show)\n",
    "mean_likelihood_noshow = np.mean(likelihoods_noshow)\n",
    "\n",
    "print(\"Mean likelihood for a client that has shown up for meetings:\", mean_likelihood_show)\n",
    "print(\"Mean likelihood for no show client:\", mean_likelihood_noshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349d018b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:03:07.023223Z",
     "start_time": "2024-04-05T14:03:06.558885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean likelihood for a client without an activated instrument ladder: 0.32519890665300943\n",
      "Mean likelihood for a client with an activated instrument ladder: 0.2574511158650173\n"
     ]
    }
   ],
   "source": [
    "# instrument_ladder_huidig_activering // instrument ladder is currently activated\n",
    "likelihoods_notactivated = []\n",
    "likelihoods_activated = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for a client without an activated instrument ladder\n",
    "    X_sample_notactivated = X_sample.copy()\n",
    "    X_sample_notactivated['instrument_ladder_huidig_activering'] = 0.0\n",
    "    y_proba_notactivated = testing_session.run(None, {'X': X_sample_notactivated.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Make predictions for a client with an activated instrument ladder\n",
    "    X_sample_activated = X_sample.copy()\n",
    "    X_sample_activated['instrument_ladder_huidig_activering'] = 1.0\n",
    "    y_proba_activated = testing_session.run(None, {'X': X_sample_activated.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Append the likelihoods for both age groups\n",
    "    likelihoods_notactivated.append([y_proba_notactivated[1]])  # Probability of class 1 (fraud) for a client without an activated instrument ladder\n",
    "    likelihoods_activated.append([y_proba_activated[1]])  # Probability of class 1 (fraud) for a client with an activated instrument ladder\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_notactivated = np.array(likelihoods_notactivated)\n",
    "likelihoods_activated = np.array(likelihoods_activated)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_notactivated = np.mean(likelihoods_notactivated)\n",
    "mean_likelihood_activated = np.mean(likelihoods_activated)\n",
    "\n",
    "print(\"Mean likelihood for a client without an activated instrument ladder:\", mean_likelihood_notactivated)\n",
    "print(\"Mean likelihood for a client with an activated instrument ladder:\", mean_likelihood_activated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9011c2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:03:07.523505Z",
     "start_time": "2024-04-05T14:03:07.023474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean likelihood for a client without a successful instrumentation history: 0.35310968828559536\n",
      "Mean likelihood for a client with a successful instrumentation history: 0.29133165888561946\n"
     ]
    }
   ],
   "source": [
    "# instrument_reden_beeindiging_historie_succesvol // successful instrumentation history\n",
    "likelihoods_not = []\n",
    "likelihoods_successful = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for a client without a successful instrumentation history\n",
    "    X_sample_not = X_sample.copy()\n",
    "    X_sample_not['instrument_reden_beeindiging_historie_succesvol'] = 0.0\n",
    "    y_proba_not = testing_session.run(None, {'X': X_sample_not.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Make predictions for a client with a successful instrumentation history\n",
    "    X_sample_successful = X_sample.copy()\n",
    "    X_sample_successful['instrument_reden_beeindiging_historie_succesvol'] = 1.0\n",
    "    y_proba_successful = testing_session.run(None, {'X': X_sample_successful.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Append the likelihoods for both age groups\n",
    "    likelihoods_not.append([y_proba_not[1]])  # Probability of class 1 (fraud) for a client without a successful instrumentation history\n",
    "    likelihoods_successful.append([y_proba_successful[1]])  # Probability of class 1 (fraud) for a client with a successful instrumentation history\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_not = np.array(likelihoods_not)\n",
    "likelihoods_successful = np.array(likelihoods_successful)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_not = np.mean(likelihoods_not)\n",
    "mean_likelihood_successful = np.mean(likelihoods_successful)\n",
    "\n",
    "print(\"Mean likelihood for a client without a successful instrumentation history:\", mean_likelihood_not)\n",
    "print(\"Mean likelihood for a client with a successful instrumentation history:\", mean_likelihood_successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735462f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:03:10.685715Z",
     "start_time": "2024-04-05T14:03:10.229567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for age 25 and 65: 7.908264136022143e-05\n",
      "Mean likelihood for a 25 year old: 0.4007646592769193\n",
      "Mean likelihood for a 35 year old: 0.37043097029094313\n",
      "Mean likelihood for a 45 year old: 0.24840444514005727\n",
      "Mean likelihood for a 55 year old: 0.22172107294926582\n",
      "Mean likelihood for a 65 year old: 0.6351792189857148\n"
     ]
    }
   ],
   "source": [
    "# Age test\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "likelihoods_25 = []\n",
    "likelihoods_35 = []\n",
    "likelihoods_45 = []\n",
    "likelihoods_55 = []\n",
    "likelihoods_65 = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for age 25\n",
    "    X_sample_25 = X_sample.copy()\n",
    "    X_sample_25['persoon_leeftijd_bij_onderzoek'] = 25\n",
    "    y_pred_25 = testing_session.run(None, {'X': X_sample_25.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for age 35\n",
    "    X_sample_35 = X_sample.copy()\n",
    "    X_sample_35['persoon_leeftijd_bij_onderzoek'] = 35\n",
    "    y_pred_35 = testing_session.run(None, {'X': X_sample_35.values.astype(np.float32)})\n",
    "    \n",
    "    # Make predictions for age 45\n",
    "    X_sample_45 = X_sample.copy()\n",
    "    X_sample_45['persoon_leeftijd_bij_onderzoek'] = 45\n",
    "    y_pred_45 = testing_session.run(None, {'X': X_sample_45.values.astype(np.float32)})\n",
    "    \n",
    "    # Make predictions for age 55\n",
    "    X_sample_55 = X_sample.copy()\n",
    "    X_sample_55['persoon_leeftijd_bij_onderzoek'] = 55\n",
    "    y_pred_55 = testing_session.run(None, {'X': X_sample_55.values.astype(np.float32)})\n",
    "    \n",
    "    # Make predictions for age 65\n",
    "    X_sample_65 = X_sample.copy()\n",
    "    X_sample_65['persoon_leeftijd_bij_onderzoek'] = 65\n",
    "    y_pred_65 = testing_session.run(None, {'X': X_sample_65.values.astype(np.float32)})\n",
    "    \n",
    "    # Append the likelihoods for both groups\n",
    "    likelihoods_25.append([y_pred_25[1][0][1]])\n",
    "    likelihoods_35.append([y_pred_35[1][0][1]])\n",
    "    likelihoods_45.append([y_pred_45[1][0][1]])\n",
    "    likelihoods_55.append([y_pred_55[1][0][1]])\n",
    "    likelihoods_65.append([y_pred_65[1][0][1]])\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_25 == y_pred_65:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_25 = np.array(likelihoods_25)\n",
    "likelihoods_35 = np.array(likelihoods_35)\n",
    "likelihoods_45 = np.array(likelihoods_45)\n",
    "likelihoods_55 = np.array(likelihoods_55)\n",
    "likelihoods_65 = np.array(likelihoods_65)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_25 = np.mean(likelihoods_25)\n",
    "mean_likelihood_35 = np.mean(likelihoods_35)\n",
    "mean_likelihood_45 = np.mean(likelihoods_45)\n",
    "mean_likelihood_55 = np.mean(likelihoods_55)\n",
    "mean_likelihood_65 = np.mean(likelihoods_65)\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for age 25 and 65:\", fraction_same_predictions)\n",
    "print(\"Mean likelihood for a 25 year old:\", mean_likelihood_25)\n",
    "print(\"Mean likelihood for a 35 year old:\", mean_likelihood_35)\n",
    "print(\"Mean likelihood for a 45 year old:\", mean_likelihood_45)\n",
    "print(\"Mean likelihood for a 55 year old:\", mean_likelihood_55)\n",
    "print(\"Mean likelihood for a 65 year old:\", mean_likelihood_65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b0931b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:03:11.645063Z",
     "start_time": "2024-04-05T14:03:11.196094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for men and women: 0.0\n",
      "Mean likelihood for a man: 0.09018988074781208\n",
      "Mean likelihood for a woman: 0.5208941890393005\n"
     ]
    }
   ],
   "source": [
    "# Gender test\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "likelihoods_men = []\n",
    "likelihoods_women = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for men\n",
    "    X_sample_men = X_sample.copy()\n",
    "    X_sample_men['persoon_geslacht_vrouw'] = 0.0\n",
    "    y_pred_men = testing_session.run(None, {'X': X_sample_men.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for women\n",
    "    X_sample_women = X_sample.copy()\n",
    "    X_sample_women['persoon_geslacht_vrouw'] = 1.0\n",
    "    y_pred_women = testing_session.run(None, {'X': X_sample_women.values.astype(np.float32)})\n",
    "    \n",
    "    \n",
    "    # Append the likelihoods for both groups\n",
    "    likelihoods_men.append([y_pred_men[1][0][1]])\n",
    "    likelihoods_women.append([y_pred_women[1][0][1]])\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_men == y_pred_women:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_men = np.array(likelihoods_men)\n",
    "likelihoods_women = np.array(likelihoods_women)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_men = np.mean(likelihoods_men)\n",
    "mean_likelihood_women = np.mean(likelihoods_women)\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for men and women:\", fraction_same_predictions)\n",
    "print(\"Mean likelihood for a man:\", mean_likelihood_men)\n",
    "print(\"Mean likelihood for a woman:\", mean_likelihood_women)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "975e7e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:03:12.432104Z",
     "start_time": "2024-04-05T14:03:11.963730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for dutch speakers and non-dutch speakers: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Language test \n",
    "# persoonlijke_eigenschappen_spreektaal_anders\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for not\n",
    "    X_sample_not = X_sample.copy()\n",
    "    X_sample_not['persoonlijke_eigenschappen_spreektaal_anders'] = 0.0\n",
    "    y_pred_not = testing_session.run(None, {'X': X_sample_not.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for other language\n",
    "    X_sample_other = X_sample.copy()\n",
    "    X_sample_other['persoonlijke_eigenschappen_spreektaal_anders'] = 1.0\n",
    "    y_pred_other = testing_session.run(None, {'X': X_sample_other.values.astype(np.float32)})\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_not == y_pred_other:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for dutch speakers and non-dutch speakers:\", fraction_same_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e72a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for unknown language speakers and known language speakers: 0.0007908264136022143\n",
      "Mean likelihood for a client speaking unknown language: 0.3105974809932068\n",
      "Mean likelihood for a client speaking language 4: 0.27691621925105875\n"
     ]
    }
   ],
   "source": [
    "# Language test\n",
    "# persoonlijke_eigenschappen_spreektaal [57  0 96 73 99  2 95 70  3  1 19 59  4 25 61 14  9  5]\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "likelihoods_language_0 = []\n",
    "likelihoods_language_4 = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "    \n",
    "    # Make predictions for language 0\n",
    "    X_sample_language_0 = X_sample.copy()\n",
    "    X_sample_language_0['persoonlijke_eigenschappen_spreektaal'] = 0\n",
    "    y_pred_language_0 = testing_session.run(None, {'X': X_sample_language_0.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for language 4\n",
    "    X_sample_language_4 = X_sample.copy()\n",
    "    X_sample_language_4['persoonlijke_eigenschappen_spreektaal'] = 4\n",
    "    y_pred_language_4 = testing_session.run(None, {'X': X_sample_language_4.values.astype(np.float32)})\n",
    "    \n",
    "    # Append the likelihoods for both groups\n",
    "    likelihoods_language_0.append([y_pred_language_0[1][0][1]])\n",
    "    likelihoods_language_4.append([y_pred_language_4[1][0][1]])\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_language_0 == y_pred_language_4:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_language_0 = np.array(likelihoods_language_0)\n",
    "likelihoods_language_4 = np.array(likelihoods_language_4)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihoods_language_0 = np.mean(likelihoods_language_0)\n",
    "mean_likelihood_language_4 = np.mean(likelihoods_language_4)\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for unknown language speakers and known language speakers:\", fraction_same_predictions)\n",
    "print(\"Mean likelihood for a client speaking unknown language:\", mean_likelihoods_language_0)\n",
    "print(\"Mean likelihood for a client speaking language 4:\", mean_likelihood_language_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408f31c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:03:12.955432Z",
     "start_time": "2024-04-05T14:03:12.431189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for people with or without children: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Children test\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for no children\n",
    "    X_sample_not = X_sample.copy()\n",
    "    X_sample_not['relatie_kind_heeft_kinderen'] = 0.0\n",
    "    y_pred_not = testing_session.run(None, {'X': X_sample_not.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for client having children\n",
    "    X_sample_children = X_sample.copy()\n",
    "    X_sample_children['relatie_kind_heeft_kinderen'] = 1.0\n",
    "    y_pred_children = testing_session.run(None, {'X': X_sample_children.values.astype(np.float32)})\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_not == y_pred_children:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for people with or without children:\", fraction_same_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f7e6bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for people with 3 children or without children: 0.00039541320680110717\n",
      "Mean likelihood for a client with 0 children: 0.2504962330705425\n",
      "Mean likelihood for a client with 3 children: 0.30818252696874066\n"
     ]
    }
   ],
   "source": [
    "# Children test\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "likelihoods_0_children = []\n",
    "likelihoods_3_children = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for 0 children\n",
    "    X_sample_0_children = X_sample.copy()\n",
    "    X_sample_0_children['relatie_kind_huidige_aantal'] = 0.0\n",
    "    y_pred_0_children = testing_session.run(None, {'X': X_sample_0_children.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for 3 children\n",
    "    X_sample_3_children = X_sample.copy()\n",
    "    X_sample_3_children['relatie_kind_huidige_aantal'] = 3.0\n",
    "    y_pred_3_children = testing_session.run(None, {'X': X_sample_3_children.values.astype(np.float32)})\n",
    "    \n",
    "    # Append the likelihoods for both groups\n",
    "    likelihoods_0_children.append([y_pred_0_children[1][0][1]])\n",
    "    likelihoods_3_children.append([y_pred_3_children[1][0][1]])\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_0_children == y_pred_3_children:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_0_children = np.array(likelihoods_0_children)\n",
    "likelihoods_3_children = np.array(likelihoods_3_children)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_0_children = np.mean(likelihoods_0_children)\n",
    "mean_likelihood_3_children = np.mean(likelihoods_3_children)\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for people with 3 children or without children:\", fraction_same_predictions)\n",
    "print(\"Mean likelihood for a client with 0 children:\", mean_likelihood_0_children)\n",
    "print(\"Mean likelihood for a client with 3 children:\", mean_likelihood_3_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "972b7d01d29103b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('adres',\n",
       " 'woonadres',\n",
       " 'verzendadres',\n",
       " 'buurt',\n",
       " 'wijk',\n",
       " 'plaats',\n",
       " 'persoon_geslacht_vrouw',\n",
       " 'taal',\n",
       " 'kind',\n",
       " 'ontheffing',\n",
       " 'leeftijd')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"adres\", \"woonadres\", \"verzendadres\", \"buurt\", \"wijk\", \"plaats\", \"persoon_geslacht_vrouw\", \"taal\", \"kind\", \"ontheffing\", \"leeftijd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd59c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for Charlois residents or non-residents: 0.0007908264136022143\n",
      "Mean likelihood for a client living most recently in Charlois: 0.2597466821772348\n",
      "Mean likelihood for a client living most recently somewhere else: 0.29509847586029553\n"
     ]
    }
   ],
   "source": [
    "# Neighbourhood test - Find neighbourhoods with low immigrant prcentage vs high and check results\n",
    "# Charlois - higher non-western population - 51% https://opendata.cbs.nl/#/CBS/nl/dataset/85618NED/table?dl=699B7\n",
    "\n",
    "\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "likelihoods_neighbourhood_Charlois = []\n",
    "likelihoods_neighbourhood_not = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for clients most recently living in Charlois\n",
    "    X_sample_neighbourhood_Charlois = X_sample.copy()\n",
    "    X_sample_neighbourhood_Charlois['adres_recentste_wijk_charlois'] = 1.0\n",
    "    y_pred_neighbourhood_Charlois = testing_session.run(None, {'X': X_sample_neighbourhood_Charlois.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for clients most recently living in somewhere else\n",
    "    X_sample_neighbourhood_not = X_sample.copy()\n",
    "    X_sample_neighbourhood_not['adres_recentste_wijk_charlois'] = 0.0\n",
    "    y_pred_neighbourhood_not = testing_session.run(None, {'X': X_sample_neighbourhood_not.values.astype(np.float32)})\n",
    "    \n",
    "    \n",
    "    # Append the likelihoods for both groups\n",
    "    likelihoods_neighbourhood_Charlois.append([y_pred_neighbourhood_Charlois[1][0][1]])\n",
    "    likelihoods_neighbourhood_not.append([y_pred_neighbourhood_not[1][0][1]])\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_neighbourhood_Charlois == y_pred_neighbourhood_not:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_neighbourhood_Charlois = np.array(likelihoods_neighbourhood_Charlois)\n",
    "likelihoods_neighbourhood_not = np.array(likelihoods_neighbourhood_not)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_neighbourhood_Charlois = np.mean(likelihoods_neighbourhood_Charlois)\n",
    "mean_likelihood_neighbourhood_not = np.mean(likelihoods_neighbourhood_not)\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for Charlois residents or non-residents:\", fraction_same_predictions)\n",
    "print(\"Mean likelihood for a client living most recently in Charlois:\", mean_likelihood_neighbourhood_Charlois)\n",
    "print(\"Mean likelihood for a client living most recently somewhere else:\", mean_likelihood_neighbourhood_not)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b85f4c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for Prins Alexander residents or non-residents: 0.00023724792408066428\n",
      "Mean likelihood for a client living most recently in Prins Alexader: 0.3587440191497441\n",
      "Mean likelihood for a client living most recently somewhere else: 0.2887596961913631\n"
     ]
    }
   ],
   "source": [
    "# Neighbourhood test\n",
    "# Prins Alexander - lower non-western population - 33% https://opendata.cbs.nl/#/CBS/nl/dataset/85618NED/table?dl=699B7\n",
    "\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "likelihoods_neighbourhood_PA = []\n",
    "likelihoods_neighbourhood_notPA = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for clients most recently living in Prins Alexander\n",
    "    X_sample_neighbourhood_PA = X_sample.copy()\n",
    "    X_sample_neighbourhood_PA['adres_recentste_wijk_prins_alexa'] = 1.0\n",
    "    y_pred_neighbourhood_PA = testing_session.run(None, {'X': X_sample_neighbourhood_PA.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for clients most recently living somewhere else\n",
    "    X_sample_neighbourhood_notPA = X_sample.copy()\n",
    "    X_sample_neighbourhood_notPA['adres_recentste_wijk_prins_alexa'] = 0.0\n",
    "    y_pred_neighbourhood_notPA = testing_session.run(None, {'X': X_sample_neighbourhood_notPA.values.astype(np.float32)})\n",
    "    \n",
    "    \n",
    "    # Append the likelihoods for both groups\n",
    "    likelihoods_neighbourhood_PA.append([y_pred_neighbourhood_PA[1][0][1]])\n",
    "    likelihoods_neighbourhood_notPA.append([y_pred_neighbourhood_notPA[1][0][1]])\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_neighbourhood_PA == y_pred_neighbourhood_notPA:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_neighbourhood_PA = np.array(likelihoods_neighbourhood_PA)\n",
    "likelihoods_neighbourhood_notPA = np.array(likelihoods_neighbourhood_notPA)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_neighbourhood_PA = np.mean(likelihoods_neighbourhood_PA)\n",
    "mean_likelihood_neighbourhood_notPA = np.mean(likelihoods_neighbourhood_notPA)\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for Prins Alexander residents or non-residents:\", fraction_same_predictions)\n",
    "print(\"Mean likelihood for a client living most recently in Prins Alexander:\", mean_likelihood_neighbourhood_PA)\n",
    "print(\"Mean likelihood for a client living most recently somewhere else:\", mean_likelihood_neighbourhood_notPA)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
