{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa476b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:24.343821Z",
     "start_time": "2024-04-06T08:21:24.302582Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import convert_sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# define a XGBoost classifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e81b41d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:24.547121Z",
     "start_time": "2024-04-06T08:21:24.307485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "checked\n0    0.5\n1    0.5\nName: proportion, dtype: float64"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import onnxruntime as rt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('data/synth_data_for_training.csv')\n",
    "y = data['checked']\n",
    "X = data.drop(['checked'], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# check the distribution of the target variable\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f68f63d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:24.634055Z",
     "start_time": "2024-04-06T08:21:24.544494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ONNX model:  0.6598857644991213\n",
      "Precision of the ONNX model: 0.6354500111665302\n",
      "Recall of the ONNX model: 0.7500878734622144\n",
      "F1 score of the ONNX model: 0.6880264377544029\n"
     ]
    }
   ],
   "source": [
    "# Let's load the model\n",
    "new_session = rt.InferenceSession(\"model_2.onnx\")\n",
    "\n",
    "# Correctly use the numpy array for predictions\n",
    "y_pred_onnx2 = new_session.run(None, {'X': X.astype(np.float32)})\n",
    "\n",
    "# Calculate metrics using the balanced dataset\n",
    "accuracy_onnx_model = accuracy_score(y, y_pred_onnx2[0])\n",
    "f1_model = f1_score(y, y_pred_onnx2[0], average='binary')\n",
    "precision_model = precision_score(y, y_pred_onnx2[0], average='binary')\n",
    "recall_model = recall_score(y, y_pred_onnx2[0], average='binary')\n",
    "\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n",
    "print('Precision of the ONNX model:', precision_model)\n",
    "print('Recall of the ONNX model:', recall_model)\n",
    "print('F1 score of the ONNX model:', f1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[6483, 4897],\n       [2844, 8536]])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "confusion_matrix(y, y_pred_onnx2[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:24.649798Z",
     "start_time": "2024-04-06T08:21:24.630992Z"
    }
   },
   "id": "f538433374cecf19"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b05f047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:24.689139Z",
     "start_time": "2024-04-06T08:21:24.647450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "checked\n0    0.5\n1    0.5\nName: proportion, dtype: float64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how imbalanced the datasets is\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Assuming 'X' is your dataset after applying SMOTE and it's currently a numpy array\n",
    "# Convert 'X' back to a DataFrame to use 'iterrows()'\n",
    "# If 'X' originally had column names, you'll need to specify them again here.\n",
    "column_names = data.drop(['checked'], axis=1).columns\n",
    "X = pd.DataFrame(X, columns=column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:24.690228Z",
     "start_time": "2024-04-06T08:21:24.662359Z"
    }
   },
   "id": "8893f6a7cda33ba6"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39b4ba36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:30.715266Z",
     "start_time": "2024-04-06T08:21:24.706691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean likelihood for 0 developments in PLA history: 0.6197402321889027\n",
      "Mean likelihood for 25 developments in PLA history: 0.5177660040753796\n"
     ]
    }
   ],
   "source": [
    "# Metamorphic testing: (Other than fairness testing)\n",
    "# If a value changes then the prediction likelihood should change too in line with the purpose of the model \n",
    "# pla_historie_ontwikkeling 0 or 25 // number of developments in PLA history\n",
    "\n",
    "# Load the model\n",
    "testing_session = rt.InferenceSession(\"model_2.onnx\")\n",
    "\n",
    "\n",
    "# Initialize variables to store likelihoods\n",
    "likelihoods_0 = []\n",
    "likelihoods_25 = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for 0 developments in PLA history\n",
    "    X_sample_0 = X_sample.copy()\n",
    "    X_sample_0['pla_historie_ontwikkeling'] = 0\n",
    "    y_proba_0 = testing_session.run(None, {'X': X_sample_0.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Make predictions for 25 developments in PLA history\n",
    "    X_sample_25 = X_sample.copy()\n",
    "    X_sample_25['pla_historie_ontwikkeling'] = 25\n",
    "    y_proba_25 = testing_session.run(None, {'X': X_sample_25.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Append the likelihoods for both age groups\n",
    "    likelihoods_0.append([y_proba_0[1]])  # Probability of class 1 (fraud) for 0 developments in PLA history\n",
    "    likelihoods_25.append([y_proba_25[1]])  # Probability of class 1 (fraud) for 25 developments in PLA history\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_0 = np.array(likelihoods_0)\n",
    "likelihoods_25 = np.array(likelihoods_25)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_0 = np.mean(likelihoods_0)\n",
    "mean_likelihood_25 = np.mean(likelihoods_25)\n",
    "\n",
    "print(\"Mean likelihood for 0 developments in PLA history:\", mean_likelihood_0)\n",
    "print(\"Mean likelihood for 25 developments in PLA history:\", mean_likelihood_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "716dba05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:37.032779Z",
     "start_time": "2024-04-06T08:21:30.713818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean likelihood for a client that has shown up for meetings: 0.5422416541430778\n",
      "Mean likelihood for no show client: 0.6208756809389654\n"
     ]
    }
   ],
   "source": [
    "# contacten_onderwerp_no_show // Contact subject client has not shown up for meeting\n",
    "likelihoods_show = []\n",
    "likelihoods_noshow = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for a client that has shown up for meetings\n",
    "    X_sample_show = X_sample.copy()\n",
    "    X_sample_show['contacten_onderwerp_no_show'] = 0.0\n",
    "    y_proba_show = testing_session.run(None, {'X': X_sample_show.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Make predictions for no show client\n",
    "    X_sample_noshow = X_sample.copy()\n",
    "    X_sample_noshow['contacten_onderwerp_no_show'] = 1.0\n",
    "    y_proba_noshow = testing_session.run(None, {'X': X_sample_noshow.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Append the likelihoods for both age groups\n",
    "    likelihoods_show.append([y_proba_show[1]])  # Probability of class 1 (fraud) for a client that has shown up for meetings\n",
    "    likelihoods_noshow.append([y_proba_noshow[1]])  # Probability of class 1 (fraud) for no show client\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_show = np.array(likelihoods_show)\n",
    "likelihoods_noshow = np.array(likelihoods_noshow)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_show = np.mean(likelihoods_show)\n",
    "mean_likelihood_noshow = np.mean(likelihoods_noshow)\n",
    "\n",
    "print(\"Mean likelihood for a client that has shown up for meetings:\", mean_likelihood_show)\n",
    "print(\"Mean likelihood for no show client:\", mean_likelihood_noshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "349d018b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:43.026699Z",
     "start_time": "2024-04-06T08:21:37.048939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean likelihood for a client without an activated instrument ladder: 0.6102081514750927\n",
      "Mean likelihood for a client with an activated instrument ladder: 0.5257431063611184\n"
     ]
    }
   ],
   "source": [
    "# instrument_ladder_huidig_activering // instrument ladder is currently activated\n",
    "likelihoods_notactivated = []\n",
    "likelihoods_activated = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for a client without an activated instrument ladder\n",
    "    X_sample_notactivated = X_sample.copy()\n",
    "    X_sample_notactivated['instrument_ladder_huidig_activering'] = 0.0\n",
    "    y_proba_notactivated = testing_session.run(None, {'X': X_sample_notactivated.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Make predictions for a client with an activated instrument ladder\n",
    "    X_sample_activated = X_sample.copy()\n",
    "    X_sample_activated['instrument_ladder_huidig_activering'] = 1.0\n",
    "    y_proba_activated = testing_session.run(None, {'X': X_sample_activated.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Append the likelihoods for both age groups\n",
    "    likelihoods_notactivated.append([y_proba_notactivated[1]])  # Probability of class 1 (fraud) for a client without an activated instrument ladder\n",
    "    likelihoods_activated.append([y_proba_activated[1]])  # Probability of class 1 (fraud) for a client with an activated instrument ladder\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_notactivated = np.array(likelihoods_notactivated)\n",
    "likelihoods_activated = np.array(likelihoods_activated)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_notactivated = np.mean(likelihoods_notactivated)\n",
    "mean_likelihood_activated = np.mean(likelihoods_activated)\n",
    "\n",
    "print(\"Mean likelihood for a client without an activated instrument ladder:\", mean_likelihood_notactivated)\n",
    "print(\"Mean likelihood for a client with an activated instrument ladder:\", mean_likelihood_activated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9011c2b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:48.996591Z",
     "start_time": "2024-04-06T08:21:43.027048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean likelihood for a client without a successful instrumentation history: 0.6026182460109253\n",
      "Mean likelihood for a client with a successful instrumentation history: 0.5279079782810907\n"
     ]
    }
   ],
   "source": [
    "# instrument_reden_beeindiging_historie_succesvol // successful instrumentation history\n",
    "likelihoods_not = []\n",
    "likelihoods_successful = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for a client without a successful instrumentation history\n",
    "    X_sample_not = X_sample.copy()\n",
    "    X_sample_not['instrument_reden_beeindiging_historie_succesvol'] = 0.0\n",
    "    y_proba_not = testing_session.run(None, {'X': X_sample_not.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Make predictions for a client with a successful instrumentation history\n",
    "    X_sample_successful = X_sample.copy()\n",
    "    X_sample_successful['instrument_reden_beeindiging_historie_succesvol'] = 1.0\n",
    "    y_proba_successful = testing_session.run(None, {'X': X_sample_successful.values.astype(np.float32)})[1][0]\n",
    "\n",
    "    # Append the likelihoods for both age groups\n",
    "    likelihoods_not.append([y_proba_not[1]])  # Probability of class 1 (fraud) for a client without a successful instrumentation history\n",
    "    likelihoods_successful.append([y_proba_successful[1]])  # Probability of class 1 (fraud) for a client with a successful instrumentation history\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_not = np.array(likelihoods_not)\n",
    "likelihoods_successful = np.array(likelihoods_successful)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_not = np.mean(likelihoods_not)\n",
    "mean_likelihood_successful = np.mean(likelihoods_successful)\n",
    "\n",
    "print(\"Mean likelihood for a client without a successful instrumentation history:\", mean_likelihood_not)\n",
    "print(\"Mean likelihood for a client with a successful instrumentation history:\", mean_likelihood_successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "735462f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:21:54.739845Z",
     "start_time": "2024-04-06T08:21:48.994134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for age 25 and 65: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Age test\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for age 25\n",
    "    X_sample_25 = X_sample.copy()\n",
    "    X_sample_25['persoon_leeftijd_bij_onderzoek'] = 25\n",
    "    y_pred_25 = testing_session.run(None, {'X': X_sample_25.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for age 65\n",
    "    X_sample_65 = X_sample.copy()\n",
    "    X_sample_65['persoon_leeftijd_bij_onderzoek'] = 65\n",
    "    y_pred_65 = testing_session.run(None, {'X': X_sample_65.values.astype(np.float32)})\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_25 == y_pred_65:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for age 25 and 65:\", fraction_same_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b0931b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:22:00.749985Z",
     "start_time": "2024-04-06T08:21:54.744070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for men and women: 0.0\n",
      "Mean likelihood for a man: 0.36349982588121466\n",
      "Mean likelihood for a woman: 0.861941528171039\n"
     ]
    }
   ],
   "source": [
    "# Gender test\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X_sample_successful)\n",
    "\n",
    "likelihoods_men = []\n",
    "likelihoods_women = []\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for men\n",
    "    X_sample_men = X_sample.copy()\n",
    "    X_sample_men['persoon_geslacht_vrouw'] = 0.0\n",
    "    y_pred_men = testing_session.run(None, {'X': X_sample_men.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for women\n",
    "    X_sample_women = X_sample.copy()\n",
    "    X_sample_women['persoon_geslacht_vrouw'] = 1.0\n",
    "    y_pred_women = testing_session.run(None, {'X': X_sample_women.values.astype(np.float32)})\n",
    "    \n",
    "    \n",
    "    # Append the likelihoods for both groups\n",
    "    likelihoods_men.append([y_pred_men[1][0][1]])\n",
    "    likelihoods_women.append([y_pred_women[1][0][1]])\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_men == y_pred_women:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "# Convert likelihoods lists to NumPy arrays\n",
    "likelihoods_men = np.array(likelihoods_men)\n",
    "likelihoods_women = np.array(likelihoods_women)\n",
    "\n",
    "# Calculate the mean likelihoods for each group\n",
    "mean_likelihood_men = np.mean(likelihoods_men)\n",
    "mean_likelihood_women = np.mean(likelihoods_women)\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for men and women:\", fraction_same_predictions)\n",
    "print(\"Mean likelihood for a man:\", mean_likelihood_men)\n",
    "print(\"Mean likelihood for a woman:\", mean_likelihood_women)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "975e7e28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:22:06.593472Z",
     "start_time": "2024-04-06T08:22:00.704312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for dutch speakers and non-dutch speakers: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Language test\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for not\n",
    "    X_sample_not = X_sample.copy()\n",
    "    X_sample_not['persoonlijke_eigenschappen_spreektaal_anders'] = 0.0\n",
    "    y_pred_not = testing_session.run(None, {'X': X_sample_not.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for other\n",
    "    X_sample_other = X_sample.copy()\n",
    "    X_sample_other['persoonlijke_eigenschappen_spreektaal_anders'] = 1.0\n",
    "    y_pred_other = testing_session.run(None, {'X': X_sample_other.values.astype(np.float32)})\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_not == y_pred_other:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for dutch speakers and non-dutch speakers:\", fraction_same_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "408f31c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T08:22:12.664965Z",
     "start_time": "2024-04-06T08:22:06.646287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of cases where predictions are the same for people with or without children: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Children test\n",
    "# Initialize variables to store counts\n",
    "same_predictions_count = 0\n",
    "total_samples = len(X)\n",
    "\n",
    "# Iterate through each sample in the test set\n",
    "for index, row in X.iterrows():\n",
    "    # Convert the row to a DataFrame to ensure it's a DataFrame object\n",
    "    X_sample = pd.DataFrame(row).transpose()\n",
    "\n",
    "    # Make predictions for not\n",
    "    X_sample_not = X_sample.copy()\n",
    "    X_sample_not['relatie_kind_heeft_kinderen'] = 0.0\n",
    "    y_pred_not = testing_session.run(None, {'X': X_sample_not.values.astype(np.float32)})\n",
    "\n",
    "    # Make predictions for other\n",
    "    X_sample_children = X_sample.copy()\n",
    "    X_sample_children['relatie_kind_heeft_kinderen'] = 1.0\n",
    "    y_pred_children = testing_session.run(None, {'X': X_sample_children.values.astype(np.float32)})\n",
    "\n",
    "    # Check if predictions are the same\n",
    "    if y_pred_not == y_pred_children:\n",
    "        same_predictions_count += 1\n",
    "\n",
    "# Calculate the fraction of cases where the predictions are the same\n",
    "fraction_same_predictions = same_predictions_count / total_samples\n",
    "\n",
    "print(\"Fraction of cases where predictions are the same for people with or without children:\", fraction_same_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "972b7d01d29103b5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T08:22:12.665135Z",
     "start_time": "2024-04-06T08:22:12.658795Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
