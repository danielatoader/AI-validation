{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T12:10:00.198286100Z",
     "start_time": "2024-03-21T12:10:00.174309700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import convert_sklearn\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ff5ebca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aad8f912d382c1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T12:10:01.480286500Z",
     "start_time": "2024-03-21T12:10:00.183313100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "data = pd.read_csv('data/synth_data_for_training.csv')\n",
    "selected_features = pd.read_csv('data/feature_importance.csv', sep='.').head(20)['feature']\n",
    "random.seed(42)\n",
    "\n",
    "# randomize the data\n",
    "data = data.sample(frac=1, random_state=42)\n",
    "\n",
    "# split the data into train and test\n",
    "split_index = int(len(data) * 0.75)\n",
    "train = data.iloc[:split_index]\n",
    "test = data.iloc[split_index:]\n",
    "\n",
    "# modify train set to have a more balanced dataset with regards to language proficiency\n",
    "x_0 = defaultdict(list)\n",
    "x_1 = defaultdict(list)\n",
    "x_new = []\n",
    "bucket_size = 170 # days\n",
    "ratio = 0.05 # ratio of checked to unchecked for each bucket\n",
    "\n",
    "for i in range(len(train)):\n",
    "    index = int(train.iloc[i]['persoonlijke_eigenschappen_dagen_sinds_taaleis'] / bucket_size)\n",
    "    if train.iloc[i]['checked'] == 0:\n",
    "        x_0[index].append(train.iloc[i])\n",
    "    else:\n",
    "        x_1[index].append(train.iloc[i])\n",
    "\n",
    "for i in range(min(len(x_0.keys()), len(x_1.keys()))):\n",
    "    x_new += x_0[i]\n",
    "    if len(x_1[i]) / len(x_0[i]) < ratio:\n",
    "        x_new += x_1[i]\n",
    "        continue\n",
    "    n = int(len(x_0[i]) * ratio)\n",
    "    x_new += random.sample(x_1[i], n)\n",
    "\n",
    "# overwrite train set with new set\n",
    "train = pd.DataFrame(x_new)\n",
    "\n",
    "# TODO: @V changes here for other stages of the goodmodel pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ff0f82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list=list(data.columns)\n",
    "column_list.remove(\"checked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1218c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and Y and only use the selected features\n",
    "y_train = train['checked']\n",
    "X_train = train[selected_features]\n",
    "\n",
    "y_test = test['checked']\n",
    "X_test = test.drop(\"checked\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1cee5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_age=37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "45394861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter the training data for individuals over the age of 37\n",
    "X_train_over_37 = X_train[X_train['persoon_leeftijd_bij_onderzoek'] > threshold_age]\n",
    "y_train_over_37 = y_train[X_train_over_37.index]\n",
    "# Filter the training data for individuals under the age of 37\n",
    "X_train_under_37 = X_train[X_train['persoon_leeftijd_bij_onderzoek'] <= threshold_age]\n",
    "y_train_under_37 = y_train[X_train_under_37.index]\n",
    "desired_ratio=0.04\n",
    "minority_len=sum(y_train_under_37)\n",
    "majority_len=minority_len/0.03\n",
    "sampling_strategy={0:int(majority_len),1:int(minority_len)}\n",
    "# Apply SMOTE (Synthetic Minority Over-sampling Technique) to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy)\n",
    "X_train_augmented_under_37, y_train_augmented_under_37 = smote.fit_resample(X_train_under_37, y_train_under_37)\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate the augmented data with the original training data for individuals under 37\n",
    "X_train_augmented = pd.concat([X_train_augmented_under_37, X_train_over_37])\n",
    "y_train_augmented = pd.concat([y_train_augmented_under_37, y_train_over_37])\n",
    "# Ensure that the indices are reset after concatenation\n",
    "X_train_augmented.reset_index(drop=True, inplace=True)\n",
    "y_train_augmented.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02d7aa",
   "metadata": {},
   "source": [
    "#### Reshape augmented dataframe to match the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8331688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_train_df = pd.DataFrame(0, index=X_train_augmented.index, columns=X_test.columns.difference(selected_features))\n",
    "# Concatenate selected features with empty DataFrames\n",
    "X_train_new = pd.concat([X_train_augmented, empty_train_df], axis=1)\n",
    "# Reshape to match original shape\n",
    "X_train_new=X_train_new[X_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "774c19da6ac1805f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T12:10:02.074287200Z",
     "start_time": "2024-03-21T12:10:01.480286500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the original model:  0.9263124604680582\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=1, random_state=0)\n",
    "pipeline = Pipeline(steps=[('feature selection', selector), ('classification', classifier)])\n",
    "pipeline.fit(X_train_new, \n",
    "             y_train_augmented\n",
    "             )\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "original_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of the original model: ', original_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "885162f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Bucket: (19, 28.6)\n",
      "False Positive Rate: 0.06349206349206349\n",
      "False Negative Rate: 0.6774193548387096\n",
      "\n",
      "Age Bucket: (28.6, 38.2)\n",
      "False Positive Rate: 0.020761245674740483\n",
      "False Negative Rate: 0.6947368421052632\n",
      "\n",
      "Age Bucket: (38.2, 47.8)\n",
      "False Positive Rate: 0.005738880918220947\n",
      "False Negative Rate: 0.7065217391304348\n",
      "\n",
      "Age Bucket: (47.8, 57.4)\n",
      "False Positive Rate: 0.002657218777679362\n",
      "False Negative Rate: 0.8809523809523809\n",
      "\n",
      "Age Bucket: (57.4, inf)\n",
      "False Positive Rate: 0.007309941520467836\n",
      "False Negative Rate: 0.55\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4e5c510f6388e983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T12:10:02.126286200Z",
     "start_time": "2024-03-21T12:10:02.094288Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ONNX model:  0.9263124604680582\n"
     ]
    }
   ],
   "source": [
    "onnx_model = convert_sklearn(\n",
    "    pipeline, initial_types=[('X', FloatTensorType((None, X_test.shape[1])))],\n",
    "    target_opset=12)\n",
    "\n",
    "model_name = 'goodmodel'\n",
    "onnx.save(onnx_model, f'model/{model_name}.onnx')\n",
    "new_session = rt.InferenceSession(f'model/{model_name}.onnx')\n",
    "\n",
    "y_pred_onnx =  new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
