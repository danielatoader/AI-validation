{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # # TODO: The threshold of 0.5 is arbitrary and might need to be adjusted based on your specific dataset and the model you are using. For some models, even moderately correlated features might pose problems, while for others, even higher correlations might not be as concerning.\n",
    "# # # TODO: As a baseline model we can also use a model that has built-in mechanisms for feature selection (like L1 regularization for linear models). \n",
    "# # # TODO: Saga: Not checking missing values, outliers, or other data quality issues, imbalanced dataset. These can also affect the model's performance and should be addressed before or during feature selection."
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a2ed7103837bfaef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa476b3d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skl2onnx import convert_sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pingouin as pg\n",
    "# define a XGBoost classifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore runtime warnings\n",
    "# Temporarily adjust pandas display settings for large DataFrames\n",
    "pd.set_option('display.max_rows', 100)  # Ensure 100 rows can be displayed\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns can be displayed\n",
    "pd.set_option('display.width', None)  # Automatically adjust display width to terminal size\n",
    "pd.set_option('display.max_colwidth', None)  # Ensure full width of column content is shown\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)  # Format the float numbers for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing and feature selection\n",
    "\n",
    "Our data consists of binary data so we only want to calculate the Z-score for non-binary colomns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5c68733094bb7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data/synth_data_for_training.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2e74ac1f2e39d06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Before cleaning:\")\n",
    "print(\"Missing values per column:\")\n",
    "print(\"Total missing values:\", data.isna().sum().sum())\n",
    "\n",
    "# Identify non-binary columns\n",
    "non_binary_columns = [col for col in data.columns if not (np.isin(data[col].unique(), [0, 1]).all() and len(data[col].unique()) == 2)]\n",
    "\n",
    "# Calculate Z-scores for non-binary columns only\n",
    "z_scores_non_binary = np.abs(stats.zscore(data[non_binary_columns], nan_policy='omit'))\n",
    "\n",
    "# Mask to identify rows with outliers in non-binary columns\n",
    "outlier_mask = (z_scores_non_binary > 3.5).any(axis=1)\n",
    "\n",
    "# Select a subset of non-binary columns for plotting to avoid large image sizes\n",
    "plot_columns = non_binary_columns[:5]  # Adjust this number based on your specific needs\n",
    "\n",
    "# Plot outliers for the selected columns before removing\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, col in enumerate(plot_columns, 1):\n",
    "    plt.subplot(1, len(plot_columns), i)\n",
    "    sns.boxplot(y=data[col])\n",
    "    plt.title(f'Before: {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Remove outliers from the dataset using the previously defined full_outlier_mask\n",
    "data_cleaned = data[~outlier_mask]\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"Missing values per column:\")\n",
    "print(\"Total missing values:\", data_cleaned.isna().sum().sum())\n",
    "\n",
    "# Plot outliers for the selected columns after removing\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, col in enumerate(plot_columns, 1):\n",
    "    plt.subplot(1, len(plot_columns), i)\n",
    "    sns.boxplot(y=data_cleaned[col])\n",
    "    plt.title(f'After: {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the shape of the dataset before and after cleaning\n",
    "print(\"Shape before cleaning:\", data.shape)\n",
    "print(\"Shape after cleaning:\", data_cleaned.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9e08d21e4405f83b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_non_fair_features(df):\n",
    "    non_fair_keywords = [\n",
    "        \"adres\", \"woonadres\", \"verzendadres\", \"buurt\", \"wijk\", \"plaats\", \"persoon_geslacht_vrouw\", \"taal\", \"kind\"\n",
    "        , \"ontheffing\"\n",
    "    ]\n",
    "    # Optionally, define keywords for features you want to ensure are included\n",
    "    fair_inclusion_keywords = [\n",
    "        \"medische_omstandigheden\", \"sociaal_maatschappelijke_situatie\"\n",
    "    ]\n",
    "\n",
    "    # Maak de controle case-insensitive\n",
    "    non_fair_keywords = [keyword.lower() for keyword in non_fair_keywords]\n",
    "    fair_inclusion_keywords = [keyword.lower() for keyword in fair_inclusion_keywords]\n",
    "\n",
    "    # Filter features, ensuring that certain conditions are met for inclusion or exclusion\n",
    "    fair_features = [feature for feature in df.columns if not any(nfk in feature.lower() for nfk in non_fair_keywords) or any(fik in feature.lower() for fik in fair_inclusion_keywords)]\n",
    "    \n",
    "    # Keep list of removed features\n",
    "    removed_features = [feature for feature in df.columns if feature not in fair_features]\n",
    "    \n",
    "    # Retourneer een DataFrame met alleen de FAIR features\n",
    "    return df[fair_features], removed_features\n",
    "\n",
    "\n",
    "# Pas de filter toe op de DataFrame\n",
    "data_reduced, removed_features = filter_non_fair_features(data_cleaned)\n",
    "\n",
    "# print all kolomn that are removed\n",
    "print(\"Removed features:\")\n",
    "for feature in removed_features:\n",
    "    print(feature)\n",
    "\n",
    "# # Print alle kolomnamen van de gefilterde DataFrame\n",
    "print(\"\\n\\n\\nRemaining features:\")\n",
    "for col in data_reduced.columns:\n",
    "    print(col)\n",
    "    \n",
    "# Print the shape of the dataset before and after filtering\n",
    "print(\"\\nShape before filtering:\", data_cleaned.shape)\n",
    "print(\"Shape after filtering:\", data_reduced.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6f80c92f08df57db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming data_reduced_scaled is already your standardized data\n",
    "# Standardize the Data (you've already done this part)\n",
    "scaler = StandardScaler()\n",
    "data_reduced_scaled = scaler.fit_transform(data_reduced)\n",
    "\n",
    "# Determine the number of components\n",
    "pca = PCA().fit(data_reduced_scaled)\n",
    "\n",
    "# Calculate the cumulative sum of explained variance ratio\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the elbow plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--')\n",
    "plt.title('PCA Elbow Plot')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "\n",
    "# Optional: Add a threshold line, e.g., 0.95 for 95% explained variance\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cbe56b7e917e3d97",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming data_reduced_scaled is your standardized data\n",
    "# Perform PCA to retain 95% of the variance\n",
    "pca = PCA(n_components=0.95)\n",
    "data_reduced_pca = pca.fit_transform(data_reduced_scaled)\n",
    "\n",
    "# Convert the PCA result back into a pandas DataFrame\n",
    "# Create column names based on the number of selected components\n",
    "columns = [f'PC{i+1}' for i in range(data_reduced_pca.shape[1])]\n",
    "data_reduced_df = pd.DataFrame(data_reduced_pca, columns=columns)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "25ccca9a6637ce55",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check how imbalance the dataset is\n",
    "data_reduced['checked'].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b46ed9aaadbf46b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81b41d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Let's specify the features and the target\n",
    "y = data_reduced['checked']\n",
    "X = data_reduced.drop(['checked'], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# TODO: Instead of a single train-test split, consider using cross-validation to assess model performance more robustly. This approach can help ensure the model's generalizability across different subsets of our data.\n",
    "# Let's split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# TODO: Further explore feature engineering possibilities. Creating new features based on domain knowledge can provide the model with additional insights, potentially improving performance\n",
    "\n",
    "# Initializing and training the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Getting feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Converting feature importances into a more readable format\n",
    "features = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sorting features by importance\n",
    "features_sorted = features.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting the top 50 features\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=features_sorted.head(50))\n",
    "plt.title('Top 50 features')\n",
    "plt.show()"
   ],
   "id": "e328aa62037109b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature scaling and model training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e8911074abf9ebe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5a3c6",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "classifier = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    # scale_pos_weight=(len(y_train) - sum(y_train)) / sum(y_train),\n",
    "    use_label_encoder=False,  # To avoid warning\n",
    "    eval_metric='logloss',  # Evaluation metric to avoid warning\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Create a pipeline object with our selector and classifier\n",
    "# NOTE: You can create custom pipeline objects but they must be registered to onnx or it will not recognise them\n",
    "# Because of this we recommend using the onnx known objects as defined in the documentation\n",
    "# TODO: The pipeline construction and inclusion of feature scaling via StandardScaler is a good practice, ensuring that your model is not biased by the scale of the features.\n",
    "pipeline_steps = [\n",
    "    ('classification', classifier)\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps=pipeline_steps)\n",
    "\n",
    "# Let's train a simple model\n",
    "pipeline.fit(X_train, y_train)"
   ],
   "id": "d8ae8fe8386fc9aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# TODO: Our evaluation focuses on accuracy, which is a good starting point. However, for fraud detection, other metrics like Precision, Recall, F1 Score, or even a custom cost function might be more appropriate due to the typically imbalanced nature of fraud data. This helps ensure you're not only capturing the fraud cases accurately but also minimizing false positives which can be costly or disruptive.\n",
    "# Let's evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Adjust the classification threshold\n",
    "threshold = 0.9  # Set this to the new threshold you want to test\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]  # Get the probabilities for the positive class\n",
    "y_pred_adjusted = (y_pred_proba >= threshold).astype(int)  # Apply the new threshold to make predictions\n",
    "\n",
    "# Evaluate the adjusted predictions\n",
    "accuracy_adjusted = accuracy_score(y_test, y_pred_adjusted)\n",
    "precision_adjusted = precision_score(y_test, y_pred_adjusted)\n",
    "recall_adjusted = recall_score(y_test, y_pred_adjusted)\n",
    "f1_adjusted = f1_score(y_test, y_pred_adjusted)\n",
    "\n",
    "print(f'Adjusted Accuracy: {accuracy_adjusted:.4f}')\n",
    "print(f'Adjusted Precision: {precision_adjusted:.4f}')\n",
    "print(f'Adjusted Recall: {recall_adjusted:.4f}')\n",
    "print(f'Adjusted F1 Score: {f1_adjusted:.4f}')\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_adjusted)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['No Fraud', 'Fraud'], yticklabels=['No Fraud', 'Fraud'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ],
   "id": "aeab6096d853145e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Let's convert the model to ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "    target_opset=12)\n",
    "\n",
    "# Let's check the accuracy of the converted model\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ],
   "id": "be836516cb7dd1f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68f63d",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Let's save the model\n",
    "onnx.save(onnx_model, \"model/good_model.onnx\")\n",
    "\n",
    "# Let's load the model\n",
    "new_session = rt.InferenceSession(\"model/good_model.onnx\")\n",
    "\n",
    "# Let's predict the target\n",
    "y_pred_onnx2 =  new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx2[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6429d69ef0396d17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
