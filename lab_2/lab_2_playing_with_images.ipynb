{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T15:00:27.111882Z",
     "start_time": "2024-02-23T15:00:27.083013Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (image_models.py, line 44)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3550\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 4\u001b[0;36m\n\u001b[0;31m    from helpers.image_models import ImagePrediction\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/AI-validation/lab_2/helpers/image_models.py:44\u001b[0;36m\u001b[0m\n\u001b[0;31m    match model_name:\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Import relevant modules\n",
    "# ImagePrediction is a helper module (helpers/image_models) that assists with setting up the image recognition models\n",
    "# and getting a prediction.\n",
    "from helpers.image_models import ImagePrediction\n",
    "# Ground truth helper so we can see the ground truth of an Imagenet image.\n",
    "from validate_ground_truth.imagenet_ground_truth import ImagenetGroundTruth\n",
    "# Instantiates the ImagePrediction object with the vgg16 model\n",
    "predictor = ImagePrediction(model_name=\"vgg16\")\n",
    "# Instantiates the ImagenetGroundTruth object\n",
    "ground_truth = ImagenetGroundTruth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T15:00:27.095024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Will use the predictor to give us a prediction fitness for the llama image.\n",
    "print(predictor.get_prediction(\"./random_images/llama.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T15:00:27.096126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Will use the predictor to give us a prediction fitness for the truck image.\n",
    "print(predictor.get_prediction(\"./random_images/truck.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T15:00:27.097932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gets the prediction for the Imagenet image 'grey_fox' and validates if the ground_truth for this image is correct.\n",
    "prediction = predictor.get_prediction(\"./imagenet_images/ILSVRC2012_val_00000323.JPEG\")\n",
    "print(prediction)\n",
    "print(ground_truth.validate_ground_truth(\"imagenet_images/ILSVRC2012_val_00000323.JPEG\", prediction[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T15:00:27.099746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gets the fitness prediction for the arctic fox image.\n",
    "arctic_fox = predictor.get_prediction(\"./random_images/arctic-fox.jpg\")\n",
    "print(arctic_fox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T15:00:27.101131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gets the fitness prediction for the arctic fox sepia image.\n",
    "# This is the same image as arctic fox but simply modified to be a sepia colour.\n",
    "arctic_fox_sepia = predictor.get_prediction(\"./random_images/arctic-fox-sepia.jpg\")\n",
    "print(arctic_fox_sepia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T15:00:27.102592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gives us the amount the fitness has decreased between the original and sepia image.\n",
    "# We can see that by just applying a very small change in colour to the image, that we can already reduce the fitness.\n",
    "print(arctic_fox[0][2] - arctic_fox_sepia[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T15:00:27.103987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your task now is to expand on this experiment by manually making changes to the provided images as well as any other images you can find.\n",
    "# Start by running the image through the predictor to get a baseline fitness.\n",
    "# Then copy and modify the image to see what effect this has on the fitness.\n",
    "# Are there any situations where you can flip the top-1 prediction by making these changes to the image.\n",
    "# (NOTE - This may be easier with an image that already has a low prediction fitness to begin with)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T15:00:27.105315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just like in the lecture (Leonhard's dog picture) you could also try drawing something and seeing if the model is able to predict this correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('CS4370-Ozgfi3NM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97666b196638f24d7ab12e1d9bb763b82228415352c3dcf19abb3d6d02379789"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
